{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting main follower arm.\n",
      "Activating torque on main follower arm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robot/miniconda3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Position in Robot Coordinate System:\n",
      " [-0.16006234  0.23675912  0.0189676 ]\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA GeForce RTX 4070/PCIe/SSE2\n",
      "GL_VERSION=3.3.0 NVIDIA 550.54.15\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30 NVIDIA via Cg compiler\n",
      "pthread_getconcurrency()=0\n",
      "Version = 3.3.0 NVIDIA 550.54.15\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA GeForce RTX 4070/PCIe/SSE2\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = NVIDIA Corporation\n",
      "ven = NVIDIA Corporation\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.robot_devices.motors.dynamixel import DynamixelMotorsBus\n",
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import numpy as np\n",
    "\n",
    "follower_port = \"/dev/ttyUSB1\"\n",
    "\n",
    "follower_arm = DynamixelMotorsBus(\n",
    "    port=follower_port,\n",
    "    motors={\n",
    "        # name: (index, model)\n",
    "        \"shoulder_pan\": (1, \"xl430-w250\"),\n",
    "        \"shoulder_lift\": (2, \"xl430-w250\"),\n",
    "        \"elbow_flex\": (3, \"xl330-m288\"),\n",
    "        \"wrist_flex\": (4, \"xl330-m288\"),\n",
    "        \"wrist_roll\": (5, \"xl330-m288\"),\n",
    "        \"gripper\": (6, \"xl330-m288\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "from lerobot.common.robot_devices.robots.manipulator import ManipulatorRobot\n",
    "from lerobot.common.robot_devices.cameras.opencv import OpenCVCamera\n",
    "\n",
    "robot = ManipulatorRobot(\n",
    "    robot_type=\"koch\",\n",
    "    follower_arms={\"main\": follower_arm},\n",
    "    calibration_dir=\".cache/calibration/koch\",\n",
    "    cameras={\n",
    "        \"view1\": OpenCVCamera(12, fps=30, width=640, height=480),\n",
    "    },\n",
    ")\n",
    "robot.connect()\n",
    "from lerobot.common.robot_devices.motors.dynamixel import TorqueMode\n",
    "robot.follower_arms[\"main\"].write(\"Torque_Enable\", TorqueMode.ENABLED.value)\n",
    "import time\n",
    "from lerobot.scripts.control_robot import busy_wait\n",
    "\n",
    "record_time_s = 1\n",
    "fps = 60\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "\n",
    "\n",
    "base_points_camera = np.array([\n",
    "    [0.10544403, -0.18065751, 0.55699998],  # 第一个基座点\n",
    "    [0.09391508, -0.16818333, 0.55000001],  # 第二个基座点\n",
    "    [0.11092141, -0.16563238, 0.55000001]   # 第三个基座点\n",
    "])\n",
    "\n",
    "target_position_camera = np.array([-0.024, 0.0381, 0.425])\n",
    "\n",
    "\n",
    "def calculate_local_coordinate_system(base_points_camera):\n",
    "    p1, p2, p3 = base_points_camera\n",
    "\n",
    "    z_axis = np.cross(p2 - p1, p3 - p1)\n",
    "    z_axis /= np.linalg.norm(z_axis) \n",
    "\n",
    "    midpoint = (p1 + p3) / 2\n",
    "    y_axis = p2 - midpoint\n",
    "    y_axis /= np.linalg.norm(y_axis) \n",
    "\n",
    "    x_axis = np.cross(y_axis, z_axis)\n",
    "    x_axis /= np.linalg.norm(x_axis)  \n",
    "\n",
    "    rotation_matrix = np.vstack([x_axis, y_axis, z_axis]).T\n",
    "\n",
    "    return rotation_matrix\n",
    "\n",
    "rotation_matrix = calculate_local_coordinate_system(base_points_camera)\n",
    "\n",
    "base_point_robot = np.array([0, 0, 0])\n",
    "translation_vector = base_point_robot - rotation_matrix.dot(base_points_camera[0])\n",
    "\n",
    "def transform_target_position(target_position_camera, rotation_matrix, translation_vector):\n",
    "    target_position_robot = rotation_matrix.dot(target_position_camera) + translation_vector\n",
    "    return target_position_robot\n",
    "\n",
    "target_position_robot = transform_target_position(target_position_camera, rotation_matrix, translation_vector)\n",
    "print(\"Target Position in Robot Coordinate System:\\n\", target_position_robot)\n",
    "p.connect(p.GUI)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "robot_id = p.loadURDF(\"/home/rhos/Desktop/LeapTele/DexCopilot/assets/low_cost_robot_description/urdf/low_cost_robot.urdf\", useFixedBase=True)\n",
    "visual_shape_id = p.createVisualShape(\n",
    "    shapeType=p.GEOM_SPHERE,\n",
    "    radius=0.01,  \n",
    "    rgbaColor=[1, 0, 0, 1]  \n",
    ")\n",
    "\n",
    "p.createMultiBody(\n",
    "    baseMass=0,\n",
    "    baseVisualShapeIndex=visual_shape_id,\n",
    "    basePosition=target_position_robot\n",
    ")\n",
    "\n",
    "for _ in range(10000):\n",
    "    p.stepSimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim2real(joint_angles):\n",
    "    joint_limits = [\n",
    "        (-1.5708, 1.5708),  # joint1\n",
    "        (-0.5236, 1.5708),  # joint2\n",
    "        (-1.3963, 1.5708),  # joint3\n",
    "        (0, 3.1416),        # joint4\n",
    "        (0, 3.1416),        # joint5\n",
    "        (-1.5708, 0)        # joint_gripper\n",
    "    ]\n",
    "    scaled_joint_angles = []\n",
    "    for i, angle in enumerate(joint_angles):\n",
    "        lower_limit, upper_limit = joint_limits[i]\n",
    "        scaled_angle = max(lower_limit, min(upper_limit, angle))\n",
    "        scaled_joint_angles.append(scaled_angle)\n",
    "\n",
    "    joint_angles_degrees = np.degrees(joint_angles)\n",
    "    joint_angles_real= 90 - joint_angles_degrees\n",
    "    joint_angles_real[0] -= 90\n",
    "\n",
    "    return joint_angles_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Angles in Robot Coordinate System:\n",
      " (0.41986692368744477, 0.4662828109100441, 0.1739684877707861, 0.3208293913288225, 0.04130570759719363, 0.0)\n",
      "Joint Angles in Robot Coordinate System:\n",
      " [0.41986692368744477, 0.4662828109100441, 0.1739684877707861, 0.3208293913288225, 0.04130570759719363, 0]\n"
     ]
    }
   ],
   "source": [
    "# ik calculate joints\n",
    "\n",
    "joint_angles = p.calculateInverseKinematics(robot_id, 5, target_position_robot)\n",
    "print(\"Joint Angles in Robot Coordinate System:\\n\", joint_angles)\n",
    "joint_limits = [\n",
    "    (-1.5708, 1.5708),  # joint1\n",
    "    (-0.5236, 1.5708),  # joint2\n",
    "    (-1.3963, 1.5708),  # joint3\n",
    "    (0, 3.1416),        # joint4\n",
    "    (0, 3.1416),        # joint5\n",
    "    (-1.5708, 0)        # joint_gripper\n",
    "]\n",
    "\n",
    "scaled_joint_angles = []\n",
    "for i, angle in enumerate(joint_angles):\n",
    "    lower_limit, upper_limit = joint_limits[i]\n",
    "    scaled_angle = max(lower_limit, min(upper_limit, angle))\n",
    "    scaled_joint_angles.append(scaled_angle)\n",
    "print(\"Joint Angles in Robot Coordinate System:\\n\", scaled_joint_angles)\n",
    "\n",
    "for i in range(len(scaled_joint_angles)):\n",
    "    p.resetJointState(robot_id, i, scaled_joint_angles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Angles After Degree:\n",
      " [24.05660268 26.71603712  9.96766012 18.38217007  2.36664272  0.        ]\n",
      "Joint Angles After Trans:\n",
      " [-24.05660268  63.28396288  80.03233988  71.61782993  87.63335728\n",
      "  90.        ]\n"
     ]
    }
   ],
   "source": [
    "# move to grasp pose\n",
    "\n",
    "joint_angles_degrees = np.degrees(joint_angles)\n",
    "print(\"Joint Angles After Degree:\\n\", joint_angles_degrees)\n",
    "joint_angles_real= 90 - joint_angles_degrees\n",
    "joint_angles_real[0] -= 90\n",
    "print(\"Joint Angles After Trans:\\n\", joint_angles_real)\n",
    "for _ in range(record_time_s * fps):\n",
    "    start_time = time.perf_counter()\n",
    "    follower_pos = robot.follower_arms[\"main\"].read(\"Present_Position\")  \n",
    "    robot.follower_arms[\"main\"].write(\"Goal_Position\", joint_angles_real)\n",
    "\n",
    "    dt_s = time.perf_counter() - start_time\n",
    "    busy_wait(1 / fps - dt_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasp and lift up\n",
    "robot.follower_arms[\"main\"].write(\"Goal_Position\", 0, \"gripper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_position_robot = target_position_robot\n",
    "lift_position_robot[2] += 0.1\n",
    "joint_angles = p.calculateInverseKinematics(robot_id, 5, lift_position_robot)\n",
    "joint_angles_real = sim2real(joint_angles)\n",
    "joint_angles_real[-1] = 0\n",
    "robot.follower_arms[\"main\"].write(\"Goal_Position\", joint_angles_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
